import streamlit as st
from openai import OpenAI
from gtts import gTTS
from streamlit_mic_recorder import mic_recorder
import os
import time

st.set_page_config(page_title="KisanVaani Voice Assistant", page_icon="üåæ")

st.title("üåæ KisanVaani ‚Äì Voice to Voice AI")
st.write("üé§ ‡∞Æ‡∞æ‡∞ü‡±ç‡∞≤‡∞æ‡∞°‡∞Ç‡∞°‡∞ø ‚Üí ü§ñ AI ‡∞∏‡∞Æ‡∞æ‡∞ß‡∞æ‡∞®‡∞Ç ‚Üí üîä ‡∞µ‡∞æ‡∞Ø‡∞ø‡∞∏‡±ç ‡∞≤‡±ã ‡∞µ‡∞ø‡∞®‡∞Ç‡∞°‡∞ø")

# -----------------------
# OpenAI Client
# -----------------------
client = OpenAI(api_key=st.secrets["OPENAI_API_KEY"])

# -----------------------
# Speech to Text (Whisper)
# -----------------------
def speech_to_text(audio_bytes):
    try:
        transcript = client.audio.transcriptions.create(
            model="gpt-4o-mini-transcribe",
            file=audio_bytes
        )
        return transcript.text
    except:
        return None

# -----------------------
# AI Telugu Response
# -----------------------
def ai_response(question):
    try:
        SYSTEM_PROMPT = """
        ‡∞Æ‡±Ä‡∞∞‡±Å ‡∞∞‡±à‡∞§‡±Å‡∞≤ ‡∞ï‡±ã‡∞∏‡∞Ç ‡∞∞‡±Ç‡∞™‡±ä‡∞Ç‡∞¶‡∞ø‡∞Ç‡∞ö‡∞ø‡∞® AI ‡∞∏‡∞π‡∞æ‡∞Ø‡∞ï‡±Å‡∞°‡±Å.
        ‡∞™‡∞Ç‡∞ü‡∞≤‡±Å, ‡∞™‡±Å‡∞∞‡±Å‡∞ó‡±Å‡∞≤‡±Å, ‡∞Æ‡∞Ç‡∞¶‡±Å‡∞≤ ‡∞Æ‡±ã‡∞§‡∞æ‡∞¶‡±Å, ‡∞™‡∞∂‡±Å‡∞™‡±ã‡∞∑‡∞£,
        ‡∞∞‡±Å‡∞£‡∞æ‡∞≤‡±Å, ‡∞Æ‡∞æ‡∞∞‡±ç‡∞ï‡±Ü‡∞ü‡±ç ‡∞ß‡∞∞‡∞≤‡±Å, ‡∞™‡±ç‡∞∞‡∞≠‡±Å‡∞§‡±ç‡∞µ ‡∞™‡∞•‡∞ï‡∞æ‡∞≤‡±Å ‚Äî
        ‡∞Ö‡∞®‡±ç‡∞®‡∞ø‡∞ü‡∞ø‡∞ï‡±Ä ‡∞∏‡∞∞‡∞≥‡∞Æ‡±à‡∞® ‡∞§‡±Ü‡∞≤‡±Å‡∞ó‡±Å ‡∞≠‡∞æ‡∞∑‡∞≤‡±ã ‡∞∏‡∞Æ‡∞æ‡∞ß‡∞æ‡∞®‡∞Ç ‡∞á‡∞µ‡±ç‡∞µ‡∞Ç‡∞°‡∞ø.
        """

        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": SYSTEM_PROMPT},
                {"role": "user", "content": question}
            ],
            temperature=0.4,
            max_tokens=400
        )

        return response.choices[0].message.content

    except:
        return "‚ö†Ô∏è ‡∞™‡±ç‡∞∞‡∞∏‡±ç‡∞§‡±Å‡∞§‡∞Ç ‡∞∏‡∞∞‡±ç‡∞µ‡∞∞‡±ç ‡∞¨‡∞ø‡∞ú‡±Ä‡∞ó‡∞æ ‡∞â‡∞Ç‡∞¶‡∞ø."

# -----------------------
# Text to Telugu Voice
# -----------------------
def text_to_speech(text):
    tts = gTTS(text=text, lang="te")
    filename = "response.mp3"
    tts.save(filename)
    return filename

# -----------------------
# Voice Recorder Button
# -----------------------
audio = mic_recorder(
    start_prompt="üé§ ‡∞Æ‡∞æ‡∞ü‡±ç‡∞≤‡∞æ‡∞°‡∞Ç‡∞°‡∞ø",
    stop_prompt="‚èπÔ∏è ‡∞Ü‡∞™‡±Å",
    key="recorder"
)

if audio:
    st.audio(audio["bytes"])

    # Convert speech to text
    spoken_text = speech_to_text(audio["bytes"])

    if spoken_text:
        st.success(f"‡∞Æ‡±Ä ‡∞™‡±ç‡∞∞‡∞∂‡±ç‡∞®: {spoken_text}")

        # AI answer
        answer = ai_response(spoken_text)
        st.info(f"‡∞∏‡∞Æ‡∞æ‡∞ß‡∞æ‡∞®‡∞Ç: {answer}")

        # Convert to voice
        audio_file = text_to_speech(answer)
        st.audio(audio_file)
